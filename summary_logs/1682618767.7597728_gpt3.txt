PROMPT:

Write a detailed summary of the following:


The right wing has its own version of scepticism about longtermism. To many of my conservative and libertarian friends it sounds like a programme for maximizing state power, or creating world government, for the pursuit of ill-defined, distant benefits that will likely never come to pass. In these peoples cynical but nonetheless insightful view, those who profess longtermism are, deep down, just as concerned with the immediate present and their short-term politics as is everyone else. The left- and right-wing critiques may sound very different, but both point to a difficult question: are the most ardent longtermists even capable of longtermism themselves?
Another practical question is how much longtermism, properly applied, truly changes our decision calculus. One response to longtermism, not so much a critique as a partial surrender, is to argue that the best preparation for the long run is to invest in human talent, high-quality institutions and flexible responses today. Those moves may not always look like long-run investments, but perhaps they are. After all, can we be so sure about the exact form that long-term risk will take? Will we have to deflect an asteroid at short notice, fight off an evil AI entity, win a world war (and prevent a nuclear catastrophe) or deal with a supervolcano (the last one occurred 26,500 years ago)? No one can know such things. But what we do know is that talent and good, flexible institutions can help us to deal with all these potential dilemmas and more. In this view the gap between long-, medium- and short-run considerations is closed considerably. After all, human talent and good, flexible institutions should help us to deal with current problems too. And to the extent that these arguments succeed, everyone can be happy, even if not everyone prefers the longtermist mode of discourse. I call this the consilience version of long-termism.
But before we let that satisfy us, we need to ask whether talent and good institutions should always be the priority for dealing with longer-term and existential risks. And are there any downsides to these apparently beneficial things? Let us consider, for example, a biomedical research centre that studies immunology and produces frontier-level scientific innovation. One might argue that the best thing to do with such a centre would be to invest in and expand, it. Many longtermists are, however, less certain. They fear that superior knowledge of the human immune system will at some point enable terrorists or evil governments to design a deadly pathogen, able, for example, to go far beyond Covid in its carnage. And some suggest that humanity should stop research into frontier-level immunology altogether.
The counter-argument runs thus: even if we fear advances in immunology, is it not better for non-rogue actors to have the greatest understanding possible? Would it not, more simply, be better for the West to be ahead of China and Russia in this field? Might the West not need superior immunology to fend off a terror attack one day? And what of those potential rogue actors who are not ceasing their own research? Above all, what would it be like to have a government that banned an entire scientific field? And might science as a whole then stagnate, stifling our ability to divert that large asteroid heading towards the planet? (A version of this debate recently erupted when more than 1,000 artificial-intelligence experts and investors, including Elon Musk, signed an open letter calling on scientists to pause their work on large-language AI models such as ChatGPT-4 for six months. They wrote: Powerful AI systems should be developed only once we are confident that their effects will be positive and their risks will be manageable.)
The layers of argumentation pile up, and that particular question will probably never be settled. Nonetheless, the consilience approach carries one strong trump card: human beings are impatient and will probably never succeed in thinking purely about the long term. So the best we can hope to achieve, practically speaking, is to tie the long run to the short and medium runs as closely as possible. Even if consilience isnt perfect, it is perhaps the best we are going to achieve. The longtermists ought to pocket that win, knowing that they will not get much further, at least not any time soon.
In this view long-term thinking is important, but primarily because it helps us to think more clearly about the short and medium term. Most of all, we need to look for agendas where there is considerable overlap when it comes to what is best across varied time horizons. But dangers lurk in this move as well. Ive already mentioned that ostensibly long-termist agendas are often, in reality, primarily concerned with short-term political priorities. If the consilience versions of longtermism are those most likely to survive in the world of ideas, that will make it all the easier for longtermism to evolve into cloaked forms for shorter-term ambitions, dressed up in the proper analytical, rationalist language.


DETAILED SUMMARY:

==========

RESPONSE:

The right wing has its own version of scepticism about longtermism, questioning whether it is a programme for maximizing state power and creating world government for ill-defined, distant benefits. At the same time, many on the left are also sceptical, questioning whether those who profess longtermism are more concerned with immediate present and short-term politics than with the long-term. This leads to the difficult question of whether the most ardent longtermists are even capable of longtermism themselves. Another practical question is how much longtermism actually changes our decision calculus. One response is to argue that the best preparation for the long run is to invest in human talent, high-quality institutions and flexible responses today. This consilience version of long-termism closes the gap between long-, medium- and short-run considerations, but raises questions about whether talent and good institutions should always be the priority for dealing with longer-term and existential risks. It also raises questions about the potential downsides of these investments. Ultimately, it may be best to look for agendas where there is considerable overlap when it comes to what is best across varied time horizons, but there is a danger that longtermism can be used as a cloak for shorter-term ambitions.